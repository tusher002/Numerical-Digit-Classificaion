{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,AveragePooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import zlib\n",
    "import itertools\n",
    "import sklearn\n",
    "import itertools\n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, learning_curve,KFold,cross_val_score,StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:00<00:00, 375.20it/s]\n",
      "100%|██████████| 86/86 [00:00<00:00, 385.85it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 388.26it/s]\n",
      "100%|██████████| 80/80 [00:00<00:00, 382.96it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 377.65it/s]\n",
      "100%|██████████| 80/80 [00:00<00:00, 372.31it/s]\n",
      "100%|██████████| 85/85 [00:00<00:00, 383.10it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 385.99it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 376.38it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 380.71it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 373.54it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 385.76it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 378.60it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 382.57it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 378.27it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 372.00it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 370.00it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 380.50it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 375.17it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 371.12it/s]\n"
     ]
    }
   ],
   "source": [
    "imageSize=75\n",
    "train_dir = \"C:/Users/Manan/ML project_tusher/gestures/train\"\n",
    "test_dir =  \"C:/Users/Manan/ML project_tusher/gestures/validation\"\n",
    "from tqdm import tqdm\n",
    "def get_data(folder):\n",
    "    \"\"\"\n",
    "    Load the data and labels from the given folder.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for folderName in os.listdir(folder):\n",
    "        if not folderName.startswith('.'):\n",
    "            if folderName in ['0']:\n",
    "                label = 0\n",
    "            elif folderName in ['1']:\n",
    "                label = 1\n",
    "            elif folderName in ['2']:\n",
    "                label = 2\n",
    "            elif folderName in ['3']:\n",
    "                label = 3\n",
    "            elif folderName in ['4']:\n",
    "                label = 4\n",
    "            elif folderName in ['5']:\n",
    "                label = 5\n",
    "            elif folderName in ['6']:\n",
    "                label = 6\n",
    "            elif folderName in ['7']:\n",
    "                label = 7\n",
    "            elif folderName in ['8']:\n",
    "                label = 8\n",
    "            elif folderName in ['9']:\n",
    "                label = 9\n",
    "            elif folderName in ['K']:\n",
    "                label = 10\n",
    "            elif folderName in ['L']:\n",
    "                label = 11\n",
    "            elif folderName in ['M']:\n",
    "                label = 12\n",
    "            elif folderName in ['N']:\n",
    "                label = 13\n",
    "            elif folderName in ['O']:\n",
    "                label = 14\n",
    "            elif folderName in ['P']:\n",
    "                label = 15\n",
    "            elif folderName in ['Q']:\n",
    "                label = 16\n",
    "            elif folderName in ['R']:\n",
    "                label = 17\n",
    "            elif folderName in ['S']:\n",
    "                label = 18\n",
    "            elif folderName in ['T']:\n",
    "                label = 19\n",
    "            elif folderName in ['U']:\n",
    "                label = 20\n",
    "            elif folderName in ['V']:\n",
    "                label = 21\n",
    "            elif folderName in ['W']:\n",
    "                label = 22\n",
    "            elif folderName in ['X']:\n",
    "                label = 23\n",
    "            elif folderName in ['Y']:\n",
    "                label = 24\n",
    "            elif folderName in ['Z']:\n",
    "                label = 25\n",
    "            elif folderName in ['del']:\n",
    "                label = 26\n",
    "            elif folderName in ['nothing']:\n",
    "                label = 27\n",
    "            elif folderName in ['space']:\n",
    "                label = 28           \n",
    "            else:\n",
    "                label = 29\n",
    "            for image_filename in tqdm(os.listdir(folder + '/' + folderName)):\n",
    "                img_file = cv2.imread(folder + '/' + folderName + '/' + image_filename)\n",
    "                if img_file is not None:\n",
    "                    img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 3))\n",
    "                    img_arr = np.asarray(img_file)\n",
    "                    X.append(img_arr)\n",
    "                    y.append(label)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y\n",
    "X_train, y_train = get_data(train_dir) \n",
    "\n",
    "X_test, y_test = get_data(test_dir)\n",
    "\n",
    "# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_trainHot = to_categorical(y_train, num_classes = 30)\n",
    "y_testHot = to_categorical(y_test, num_classes = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, y_trainHot = shuffle(X_train, y_trainHot, random_state=13)\n",
    "X_test, y_testHot = shuffle(X_test, y_testHot, random_state=13)\n",
    "X_train = X_train[:30000]\n",
    "X_test = X_test[:30000]\n",
    "y_trainHot = y_trainHot[:30000]\n",
    "y_testHot = y_testHot[:30000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotHistogram(a):\n",
    "    \"\"\"\n",
    "    Plot histogram of RGB Pixel Intensities\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(a)\n",
    "    plt.axis('off')\n",
    "    histo = plt.subplot(1,2,2)\n",
    "    histo.set_ylabel('Count')\n",
    "    histo.set_xlabel('Pixel Intensity')\n",
    "    n_bins = 10\n",
    "    plt.hist(a[:,:,0].flatten(), bins= n_bins, lw = 0, color='r', alpha=0.5);\n",
    "    plt.hist(a[:,:,1].flatten(), bins= n_bins, lw = 0, color='g', alpha=0.5);\n",
    "    plt.hist(a[:,:,2].flatten(), bins= n_bins, lw = 0, color='b', alpha=0.5);\n",
    "plotHistogram(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_characters = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n",
    "dict_characters=map_characters\n",
    "import seaborn as sns\n",
    "df = pd.DataFrame()\n",
    "df[\"labels\"]=y_train\n",
    "lab = df['labels']\n",
    "dist = lab.value_counts()\n",
    "sns.countplot(lab)\n",
    "print(dict_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions  Learning Curves and Confusion Matrix\n",
    "\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "class MetricsCheckpoint(Callback):\n",
    "    \"\"\"Callback that saves metrics after each epoch\"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)\n",
    "\n",
    "def plotKerasLearningCurve():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (8,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot_learning_curve(history):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./accuracy_curve.png')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./loss_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 75, 75, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 75, 75, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 37, 37, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 9, 9, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                61470     \n",
      "=================================================================\n",
      "Total params: 14,776,158\n",
      "Trainable params: 61,470\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Train on 800 samples, validate on 278 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - ETA: 15s - loss: 4.0051 - accuracy: 0.0000e+0 - ETA: 15s - loss: 3.8740 - accuracy: 0.0000e+0 - ETA: 14s - loss: 3.7073 - accuracy: 0.0000e+0 - ETA: 14s - loss: 3.5357 - accuracy: 0.0078    - ETA: 14s - loss: 3.4055 - accuracy: 0.025 - ETA: 13s - loss: 3.2745 - accuracy: 0.041 - ETA: 13s - loss: 3.1396 - accuracy: 0.098 - ETA: 12s - loss: 3.0348 - accuracy: 0.117 - ETA: 11s - loss: 2.9593 - accuracy: 0.131 - ETA: 11s - loss: 2.8892 - accuracy: 0.150 - ETA: 10s - loss: 2.8095 - accuracy: 0.184 - ETA: 10s - loss: 2.7468 - accuracy: 0.205 - ETA: 9s - loss: 2.6943 - accuracy: 0.209 - ETA: 9s - loss: 2.6309 - accuracy: 0.23 - ETA: 8s - loss: 2.5736 - accuracy: 0.25 - ETA: 7s - loss: 2.5293 - accuracy: 0.27 - ETA: 6s - loss: 2.4783 - accuracy: 0.29 - ETA: 6s - loss: 2.4382 - accuracy: 0.30 - ETA: 5s - loss: 2.3972 - accuracy: 0.31 - ETA: 4s - loss: 2.3618 - accuracy: 0.32 - ETA: 3s - loss: 2.3279 - accuracy: 0.33 - ETA: 2s - loss: 2.2934 - accuracy: 0.34 - ETA: 1s - loss: 2.2617 - accuracy: 0.35 - ETA: 0s - loss: 2.2300 - accuracy: 0.37 - 35s 43ms/step - loss: 2.2023 - accuracy: 0.3837 - val_loss: 1.4541 - val_accuracy: 0.6475\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - ETA: 33s - loss: 1.4057 - accuracy: 0.843 - ETA: 30s - loss: 1.3996 - accuracy: 0.796 - ETA: 28s - loss: 1.3928 - accuracy: 0.739 - ETA: 27s - loss: 1.3509 - accuracy: 0.757 - ETA: 26s - loss: 1.3501 - accuracy: 0.762 - ETA: 24s - loss: 1.3163 - accuracy: 0.770 - ETA: 23s - loss: 1.3322 - accuracy: 0.741 - ETA: 22s - loss: 1.3292 - accuracy: 0.734 - ETA: 21s - loss: 1.3401 - accuracy: 0.722 - ETA: 19s - loss: 1.3320 - accuracy: 0.718 - ETA: 18s - loss: 1.3117 - accuracy: 0.727 - ETA: 17s - loss: 1.3149 - accuracy: 0.716 - ETA: 16s - loss: 1.3065 - accuracy: 0.716 - ETA: 14s - loss: 1.2926 - accuracy: 0.725 - ETA: 13s - loss: 1.2747 - accuracy: 0.731 - ETA: 12s - loss: 1.2666 - accuracy: 0.732 - ETA: 10s - loss: 1.2564 - accuracy: 0.739 - ETA: 9s - loss: 1.2434 - accuracy: 0.743 - ETA: 8s - loss: 1.2389 - accuracy: 0.74 - ETA: 6s - loss: 1.2320 - accuracy: 0.74 - ETA: 5s - loss: 1.2226 - accuracy: 0.74 - ETA: 4s - loss: 1.2166 - accuracy: 0.74 - ETA: 2s - loss: 1.2022 - accuracy: 0.74 - ETA: 1s - loss: 1.1869 - accuracy: 0.74 - 47s 59ms/step - loss: 1.1807 - accuracy: 0.7475 - val_loss: 1.0452 - val_accuracy: 0.7518\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - ETA: 39s - loss: 0.9296 - accuracy: 0.812 - ETA: 39s - loss: 1.0307 - accuracy: 0.781 - ETA: 35s - loss: 1.0542 - accuracy: 0.750 - ETA: 33s - loss: 1.0266 - accuracy: 0.757 - ETA: 31s - loss: 0.9904 - accuracy: 0.768 - ETA: 29s - loss: 0.9770 - accuracy: 0.765 - ETA: 27s - loss: 0.9762 - accuracy: 0.781 - ETA: 26s - loss: 0.9512 - accuracy: 0.793 - ETA: 24s - loss: 0.9434 - accuracy: 0.795 - ETA: 22s - loss: 0.9362 - accuracy: 0.803 - ETA: 21s - loss: 0.9230 - accuracy: 0.801 - ETA: 19s - loss: 0.9201 - accuracy: 0.804 - ETA: 18s - loss: 0.9210 - accuracy: 0.810 - ETA: 17s - loss: 0.9025 - accuracy: 0.819 - ETA: 15s - loss: 0.8861 - accuracy: 0.827 - ETA: 13s - loss: 0.8877 - accuracy: 0.818 - ETA: 12s - loss: 0.8783 - accuracy: 0.818 - ETA: 10s - loss: 0.8722 - accuracy: 0.819 - ETA: 9s - loss: 0.8830 - accuracy: 0.812 - ETA: 7s - loss: 0.8789 - accuracy: 0.81 - ETA: 6s - loss: 0.8770 - accuracy: 0.81 - ETA: 4s - loss: 0.8751 - accuracy: 0.81 - ETA: 3s - loss: 0.8658 - accuracy: 0.81 - ETA: 1s - loss: 0.8540 - accuracy: 0.82 - 53s 66ms/step - loss: 0.8529 - accuracy: 0.8213 - val_loss: 0.8525 - val_accuracy: 0.7770\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - ETA: 37s - loss: 0.7669 - accuracy: 0.812 - ETA: 37s - loss: 0.8502 - accuracy: 0.812 - ETA: 34s - loss: 0.7759 - accuracy: 0.854 - ETA: 32s - loss: 0.7366 - accuracy: 0.867 - ETA: 31s - loss: 0.7595 - accuracy: 0.843 - ETA: 29s - loss: 0.7435 - accuracy: 0.828 - ETA: 28s - loss: 0.7521 - accuracy: 0.817 - ETA: 27s - loss: 0.7538 - accuracy: 0.828 - ETA: 26s - loss: 0.7634 - accuracy: 0.833 - ETA: 24s - loss: 0.7635 - accuracy: 0.834 - ETA: 23s - loss: 0.7518 - accuracy: 0.835 - ETA: 21s - loss: 0.7497 - accuracy: 0.830 - ETA: 20s - loss: 0.7441 - accuracy: 0.834 - ETA: 18s - loss: 0.7318 - accuracy: 0.843 - ETA: 16s - loss: 0.7287 - accuracy: 0.847 - ETA: 14s - loss: 0.7225 - accuracy: 0.847 - ETA: 13s - loss: 0.7156 - accuracy: 0.851 - ETA: 11s - loss: 0.7038 - accuracy: 0.854 - ETA: 10s - loss: 0.7017 - accuracy: 0.852 - ETA: 8s - loss: 0.6985 - accuracy: 0.851 - ETA: 6s - loss: 0.6950 - accuracy: 0.84 - ETA: 5s - loss: 0.6989 - accuracy: 0.84 - ETA: 3s - loss: 0.6939 - accuracy: 0.85 - ETA: 1s - loss: 0.6920 - accuracy: 0.85 - 57s 71ms/step - loss: 0.6908 - accuracy: 0.8537 - val_loss: 0.7603 - val_accuracy: 0.7878\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - ETA: 37s - loss: 0.6286 - accuracy: 0.781 - ETA: 39s - loss: 0.6047 - accuracy: 0.843 - ETA: 40s - loss: 0.5877 - accuracy: 0.864 - ETA: 38s - loss: 0.6063 - accuracy: 0.851 - ETA: 36s - loss: 0.6101 - accuracy: 0.850 - ETA: 33s - loss: 0.6362 - accuracy: 0.833 - ETA: 31s - loss: 0.6350 - accuracy: 0.834 - ETA: 29s - loss: 0.6203 - accuracy: 0.847 - ETA: 27s - loss: 0.6249 - accuracy: 0.843 - ETA: 25s - loss: 0.6221 - accuracy: 0.843 - ETA: 23s - loss: 0.6181 - accuracy: 0.846 - ETA: 22s - loss: 0.6134 - accuracy: 0.851 - ETA: 20s - loss: 0.6168 - accuracy: 0.853 - ETA: 18s - loss: 0.6159 - accuracy: 0.848 - ETA: 17s - loss: 0.6155 - accuracy: 0.850 - ETA: 15s - loss: 0.6055 - accuracy: 0.853 - ETA: 13s - loss: 0.5957 - accuracy: 0.862 - ETA: 12s - loss: 0.5931 - accuracy: 0.866 - ETA: 10s - loss: 0.5902 - accuracy: 0.868 - ETA: 8s - loss: 0.5943 - accuracy: 0.867 - ETA: 6s - loss: 0.5967 - accuracy: 0.86 - ETA: 5s - loss: 0.5948 - accuracy: 0.86 - ETA: 3s - loss: 0.5925 - accuracy: 0.87 - ETA: 1s - loss: 0.5921 - accuracy: 0.87 - 59s 73ms/step - loss: 0.5889 - accuracy: 0.8737 - val_loss: 0.6775 - val_accuracy: 0.8237\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - ETA: 41s - loss: 0.5929 - accuracy: 0.843 - ETA: 37s - loss: 0.5742 - accuracy: 0.875 - ETA: 36s - loss: 0.5421 - accuracy: 0.906 - ETA: 35s - loss: 0.5139 - accuracy: 0.906 - ETA: 35s - loss: 0.5049 - accuracy: 0.906 - ETA: 33s - loss: 0.5237 - accuracy: 0.890 - ETA: 32s - loss: 0.5305 - accuracy: 0.883 - ETA: 30s - loss: 0.5368 - accuracy: 0.882 - ETA: 28s - loss: 0.5378 - accuracy: 0.888 - ETA: 26s - loss: 0.5542 - accuracy: 0.884 - ETA: 24s - loss: 0.5512 - accuracy: 0.883 - ETA: 22s - loss: 0.5489 - accuracy: 0.888 - ETA: 20s - loss: 0.5478 - accuracy: 0.891 - ETA: 19s - loss: 0.5376 - accuracy: 0.895 - ETA: 17s - loss: 0.5291 - accuracy: 0.902 - ETA: 15s - loss: 0.5306 - accuracy: 0.898 - ETA: 13s - loss: 0.5323 - accuracy: 0.897 - ETA: 12s - loss: 0.5342 - accuracy: 0.895 - ETA: 10s - loss: 0.5257 - accuracy: 0.896 - ETA: 8s - loss: 0.5274 - accuracy: 0.893 - ETA: 6s - loss: 0.5268 - accuracy: 0.89 - ETA: 5s - loss: 0.5257 - accuracy: 0.89 - ETA: 3s - loss: 0.5253 - accuracy: 0.89 - ETA: 1s - loss: 0.5226 - accuracy: 0.89 - 59s 74ms/step - loss: 0.5178 - accuracy: 0.8950 - val_loss: 0.6393 - val_accuracy: 0.8129\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - ETA: 45s - loss: 0.5851 - accuracy: 0.875 - ETA: 42s - loss: 0.5252 - accuracy: 0.875 - ETA: 40s - loss: 0.4785 - accuracy: 0.895 - ETA: 38s - loss: 0.4673 - accuracy: 0.906 - ETA: 35s - loss: 0.4543 - accuracy: 0.918 - ETA: 33s - loss: 0.4538 - accuracy: 0.916 - ETA: 31s - loss: 0.4397 - accuracy: 0.928 - ETA: 30s - loss: 0.4304 - accuracy: 0.933 - ETA: 28s - loss: 0.4297 - accuracy: 0.937 - ETA: 26s - loss: 0.4332 - accuracy: 0.937 - ETA: 24s - loss: 0.4431 - accuracy: 0.926 - ETA: 22s - loss: 0.4533 - accuracy: 0.921 - ETA: 21s - loss: 0.4496 - accuracy: 0.923 - ETA: 19s - loss: 0.4384 - accuracy: 0.928 - ETA: 17s - loss: 0.4379 - accuracy: 0.925 - ETA: 15s - loss: 0.4472 - accuracy: 0.919 - ETA: 14s - loss: 0.4468 - accuracy: 0.919 - ETA: 12s - loss: 0.4558 - accuracy: 0.916 - ETA: 10s - loss: 0.4585 - accuracy: 0.911 - ETA: 8s - loss: 0.4604 - accuracy: 0.910 - ETA: 7s - loss: 0.4655 - accuracy: 0.90 - ETA: 5s - loss: 0.4648 - accuracy: 0.90 - ETA: 3s - loss: 0.4635 - accuracy: 0.90 - ETA: 1s - loss: 0.4627 - accuracy: 0.91 - 60s 76ms/step - loss: 0.4590 - accuracy: 0.9112 - val_loss: 0.5877 - val_accuracy: 0.8453\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - ETA: 41s - loss: 0.3890 - accuracy: 0.968 - ETA: 42s - loss: 0.3871 - accuracy: 0.968 - ETA: 40s - loss: 0.4626 - accuracy: 0.927 - ETA: 38s - loss: 0.4340 - accuracy: 0.937 - ETA: 36s - loss: 0.4106 - accuracy: 0.943 - ETA: 35s - loss: 0.4144 - accuracy: 0.927 - ETA: 33s - loss: 0.4063 - accuracy: 0.928 - ETA: 30s - loss: 0.4186 - accuracy: 0.921 - ETA: 28s - loss: 0.4134 - accuracy: 0.923 - ETA: 27s - loss: 0.4084 - accuracy: 0.931 - ETA: 25s - loss: 0.4124 - accuracy: 0.929 - ETA: 23s - loss: 0.4056 - accuracy: 0.934 - ETA: 21s - loss: 0.4034 - accuracy: 0.937 - ETA: 19s - loss: 0.4062 - accuracy: 0.930 - ETA: 17s - loss: 0.4094 - accuracy: 0.927 - ETA: 16s - loss: 0.4095 - accuracy: 0.927 - ETA: 14s - loss: 0.4155 - accuracy: 0.924 - ETA: 12s - loss: 0.4203 - accuracy: 0.925 - ETA: 10s - loss: 0.4214 - accuracy: 0.924 - ETA: 9s - loss: 0.4220 - accuracy: 0.923 - ETA: 7s - loss: 0.4245 - accuracy: 0.91 - ETA: 5s - loss: 0.4202 - accuracy: 0.92 - ETA: 3s - loss: 0.4208 - accuracy: 0.92 - ETA: 1s - loss: 0.4201 - accuracy: 0.91 - 67s 83ms/step - loss: 0.4165 - accuracy: 0.9212 - val_loss: 0.5471 - val_accuracy: 0.8489\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - ETA: 1:03 - loss: 0.4747 - accuracy: 0.90 - ETA: 1:01 - loss: 0.3977 - accuracy: 0.93 - ETA: 54s - loss: 0.3838 - accuracy: 0.9375 - ETA: 49s - loss: 0.3654 - accuracy: 0.937 - ETA: 47s - loss: 0.3715 - accuracy: 0.937 - ETA: 45s - loss: 0.3821 - accuracy: 0.937 - ETA: 42s - loss: 0.4085 - accuracy: 0.915 - ETA: 40s - loss: 0.4035 - accuracy: 0.921 - ETA: 37s - loss: 0.4077 - accuracy: 0.916 - ETA: 34s - loss: 0.4050 - accuracy: 0.918 - ETA: 31s - loss: 0.4060 - accuracy: 0.920 - ETA: 28s - loss: 0.4044 - accuracy: 0.919 - ETA: 25s - loss: 0.3980 - accuracy: 0.923 - ETA: 23s - loss: 0.3963 - accuracy: 0.919 - ETA: 21s - loss: 0.3929 - accuracy: 0.922 - ETA: 19s - loss: 0.3989 - accuracy: 0.923 - ETA: 16s - loss: 0.3964 - accuracy: 0.928 - ETA: 14s - loss: 0.3947 - accuracy: 0.927 - ETA: 12s - loss: 0.3906 - accuracy: 0.929 - ETA: 10s - loss: 0.3868 - accuracy: 0.929 - ETA: 8s - loss: 0.3843 - accuracy: 0.930 - ETA: 6s - loss: 0.3864 - accuracy: 0.92 - ETA: 4s - loss: 0.3889 - accuracy: 0.92 - ETA: 2s - loss: 0.3850 - accuracy: 0.92 - 66s 83ms/step - loss: 0.3813 - accuracy: 0.9312 - val_loss: 0.5243 - val_accuracy: 0.8561\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - ETA: 41s - loss: 0.3231 - accuracy: 0.937 - ETA: 40s - loss: 0.3677 - accuracy: 0.921 - ETA: 40s - loss: 0.3501 - accuracy: 0.927 - ETA: 41s - loss: 0.3254 - accuracy: 0.945 - ETA: 41s - loss: 0.3431 - accuracy: 0.931 - ETA: 41s - loss: 0.3553 - accuracy: 0.932 - ETA: 39s - loss: 0.3539 - accuracy: 0.937 - ETA: 37s - loss: 0.3404 - accuracy: 0.941 - ETA: 34s - loss: 0.3260 - accuracy: 0.944 - ETA: 31s - loss: 0.3432 - accuracy: 0.937 - ETA: 29s - loss: 0.3499 - accuracy: 0.931 - ETA: 26s - loss: 0.3444 - accuracy: 0.937 - ETA: 24s - loss: 0.3377 - accuracy: 0.942 - ETA: 22s - loss: 0.3358 - accuracy: 0.942 - ETA: 20s - loss: 0.3349 - accuracy: 0.941 - ETA: 18s - loss: 0.3386 - accuracy: 0.943 - ETA: 16s - loss: 0.3455 - accuracy: 0.939 - ETA: 14s - loss: 0.3447 - accuracy: 0.941 - ETA: 12s - loss: 0.3465 - accuracy: 0.937 - ETA: 10s - loss: 0.3499 - accuracy: 0.934 - ETA: 8s - loss: 0.3514 - accuracy: 0.934 - ETA: 6s - loss: 0.3490 - accuracy: 0.93 - ETA: 4s - loss: 0.3468 - accuracy: 0.93 - ETA: 2s - loss: 0.3477 - accuracy: 0.93 - 69s 87ms/step - loss: 0.3474 - accuracy: 0.9375 - val_loss: 0.5012 - val_accuracy: 0.8561\n",
      "\n",
      "Keras CNN - accuracy: 0.8561151027679443 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        28\n",
      "           1       0.85      0.91      0.88        32\n",
      "           2       0.89      0.86      0.87        28\n",
      "           3       0.76      0.73      0.75        26\n",
      "           4       0.90      0.87      0.89        31\n",
      "           5       0.85      0.97      0.90        29\n",
      "           6       0.81      0.81      0.81        27\n",
      "           7       0.87      0.74      0.80        27\n",
      "           8       0.85      0.81      0.83        27\n",
      "           9       0.91      0.91      0.91        23\n",
      "\n",
      "    accuracy                           0.86       278\n",
      "   macro avg       0.86      0.85      0.85       278\n",
      "weighted avg       0.86      0.86      0.85       278\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x25de4558c08>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_characters1 = map_characters\n",
    "class_weight1 = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "weight_path1 = 'C:/Users/Manan/ML project_tusher/gestures/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "weight_path2 = 'C:/Users/Manan/ML project_tusher/gestures/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "pretrained_model_1 = VGG16(weights = weight_path1, include_top=False, input_shape=(imageSize, imageSize, 3))\n",
    "pretrained_model_2 = InceptionV3(weights = weight_path2, include_top=False, input_shape=(imageSize, imageSize, 3))\n",
    "optimizer1 = keras.optimizers.Adam()\n",
    "optimizer2 = keras.optimizers.RMSprop(lr=0.0001)\n",
    "def pretrainedNetwork(xtrain,ytrain,xtest,ytest,pretrainedmodel,pretrainedweights,classweight,numclasses,numepochs,optimizer,labels):\n",
    "    base_model = pretrained_model_1 # Topless\n",
    "    # Add top layer\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    predictions = Dense(numclasses, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    # Train top layer\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n",
    "    model.summary()\n",
    "    # Fit model\n",
    "    history = model.fit(xtrain,ytrain, epochs=numepochs, class_weight=classweight, validation_data=(xtest,ytest), verbose=1,callbacks = [MetricsCheckpoint('logs')])\n",
    "    # Evaluate model\n",
    "    score = model.evaluate(xtest,ytest, verbose=0)\n",
    "    print('\\nKeras CNN - accuracy:', score[1], '\\n')\n",
    "    y_pred = model.predict(xtest)\n",
    "    print('\\n', sklearn.metrics.classification_report(np.where(ytest > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n",
    "#     Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "#     Y_true = np.argmax(ytest,axis = 1) \n",
    "#     confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "#     plotKerasLearningCurve()\n",
    "#     plt.show()\n",
    "#     plot_learning_curve(history)\n",
    "#     plt.show()\n",
    "#     plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n",
    "#     plt.show()\n",
    "    return model\n",
    "pretrainedNetwork(X_train, y_trainHot, X_test, y_testHot,pretrained_model_1,weight_path1,class_weight1,30,10,optimizer1,map_characters1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
